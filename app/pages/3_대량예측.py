# import streamlit as st
# import pandas as pd
# import numpy as np
# import joblib
# import os
# from streamlit_extras.switch_page_button import switch_page

# # import sklearn
# # from sklearn.linear_model import LogisticRegression
# # from sklearn.ensemble import RandomForestClassifier

# st.title("ğŸ“¦ ëŒ€ëŸ‰ ì´íƒˆ ì˜ˆì¸¡ (ì‚¬ì „ ì •ì˜ íŒŒì¼ ì‚¬ìš©)")

# # 1. ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
# @st.cache_resource
# def load_model():
#     return joblib.load("../notebooks/test/log_reg.pkl")

# model = load_model()

# # 2. CSV íŒŒì¼ ê²½ë¡œ ì§ì ‘ ì§€ì •
# csv_path = "../notebooks/test/data/datasets.csv"

# if not os.path.exists(csv_path):
#     st.error(f"âŒ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {csv_path}")
# else:
#     # 3. íŒŒì¼ ì½ê¸°
#     df = pd.read_csv(csv_path)
#     st.write("âœ… ì…ë ¥ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°", df.head())

#     # 4. ì˜ˆì¸¡ ìˆ˜í–‰
#     try:
#         X = df.copy()
#         y_prob = model.predict_proba(X)[:, 1]

#         df["ì´íƒˆ í™•ë¥  (%)"] = (y_prob * 100).round(2)
#         df["ì˜ˆì¸¡ ê²°ê³¼"] = np.where(y_prob >= 0.5, "ì´íƒˆ ê°€ëŠ¥ì„± â†‘", "ì”ë¥˜ ê°€ëŠ¥ì„± â†‘")

#         st.success("âœ… ì˜ˆì¸¡ ì™„ë£Œ!")
#         st.dataframe(df[["ì´íƒˆ í™•ë¥  (%)", "ì˜ˆì¸¡ ê²°ê³¼"] + list(df.columns.difference(["ì´íƒˆ í™•ë¥  (%)", "ì˜ˆì¸¡ ê²°ê³¼"]))])

#         # 5. ë‹¤ìš´ë¡œë“œ
#         csv = df.to_csv(index=False).encode("utf-8-sig")
#         st.download_button("ğŸ“¥ ì˜ˆì¸¡ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ", data=csv, file_name="predicted_attrition.csv", mime="text/csv")

#     except Exception as e:
#         st.error(f"âŒ ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")


# import streamlit as st
# import joblib
# import pandas as pd
# import numpy as np


# bundle = joblib.load("../notebooks/test/xgb.pkl")

# st.write("ğŸ“¦ ëª¨ë¸ ë‚´ìš©:")
# st.write(type(bundle))
# if isinstance(bundle, dict):
#     st.write("ğŸ”‘ í¬í•¨ëœ í‚¤:", list(bundle.keys()))



# st.title("ğŸ“¦ ëŒ€ëŸ‰ ì´íƒˆ ì˜ˆì¸¡")

# @st.cache_resource
# def load_model():
#     return joblib.load("../notebooks/test/xgb.pkl")

# @st.cache_resource
# def load_features():
#     return joblib.load("../notebooks/test/preprocessed_columns.pkl")

# # ëª¨ë¸ ë° feature ëª©ë¡ ë¡œë”©
# model = load_model()
# feature_columns = load_features()

# def categorize(prob):
#     if prob >= 0.7:
#         return "High"
#     elif prob >= 0.3:
#         return "Medium"
#     else:
#         return "Low"

# batch_file = st.file_uploader("CSV íŒŒì¼ ì—…ë¡œë“œ", type=["csv"])

# if batch_file is not None:
#     df = pd.read_csv(batch_file)
#     st.subheader("ğŸ“‹ ì…ë ¥ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°")
#     st.dataframe(df.head())

#     # ì „ì²˜ë¦¬: ëˆ„ë½ëœ feature ì±„ìš°ê³  ì •ë ¬
#     for col in feature_columns:
#         if col not in df.columns:
#             df[col] = 0
#     X = df[feature_columns]

#     # ì˜ˆì¸¡
#     pred_proba = model.predict_proba(X)[:, 1]
#     pred = (pred_proba >= 0.5).astype(int)

#     # ê²°ê³¼ ë³‘í•©
#     df["Prob_Yes"] = np.round(pred_proba, 4)
#     df["Pred"] = np.where(pred == 1, "ì´íƒˆ", "ì”ë¥˜")
#     df["Grade"] = [categorize(p) for p in pred_proba]

#     # ê²°ê³¼ ì¶œë ¥
#     st.subheader("âœ… ì˜ˆì¸¡ ê²°ê³¼ (ìƒìœ„ 5ê°œ)")
#     st.dataframe(df[["Prob_Yes", "Pred", "Grade"]].head())

#     # ë‹¤ìš´ë¡œë“œ
#     csv = df.to_csv(index=False).encode("utf-8-sig")
#     st.download_button("ğŸ“¥ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ", data=csv, file_name="prediction_result.csv", mime="text/csv")


# import streamlit as st
# import pandas as pd
# import numpy as np
# import joblib
# import os

# st.title("ğŸ“¦ ëŒ€ëŸ‰ ì´íƒˆ ì˜ˆì¸¡ (ì „ì²˜ë¦¬ ì™„ë£Œëœ CSV ì‚¬ìš©)")

# @st.cache_resource
# def load_model():
#     return joblib.load("../notebooks/test/xgb.pkl")

# @st.cache_resource
# def load_feature_list():
#     return joblib.load("../notebooks/test/preprocessed_columns.pkl")

# model = load_model()
# feature_columns = load_feature_list()

# # ì „ì²˜ë¦¬ ì™„ë£Œëœ CSV íŒŒì¼ ê²½ë¡œ
# csv_path = "../data/processed_datasets.csv"

# if not os.path.exists(csv_path):
#     st.error(f"âŒ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {csv_path}")
# else:
#     df = pd.read_csv(csv_path)
#     st.write("âœ… ì…ë ¥ ë°ì´í„° (ì „ì²˜ë¦¬ ì™„ë£Œ)", df.head())

#     try:
#         # ëˆ„ë½ ì»¬ëŸ¼ ì±„ìš°ê¸°
#         for col in feature_columns:
#             if col not in df.columns:
#                 df[col] = 0
#         X = df[feature_columns]

#         # ì˜ˆì¸¡
#         prob = model.predict_proba(X)[:, 1]
#         pred = (prob >= 0.5).astype(int)

#         def categorize(p):
#             if p >= 0.7: return "High"
#             elif p >= 0.3: return "Medium"
#             return "Low"

#         df["Prob_Yes"] = np.round(prob, 4)
#         df["Pred"] = np.where(pred == 1, "ì´íƒˆ", "ì”ë¥˜")
#         df["Grade"] = [categorize(p) for p in prob]


#         # 5. ì´íƒˆ í™•ë¥  ë†’ì€ ìˆœìœ¼ë¡œ ì •ë ¬
#         df_sorted = df.sort_values(by="Prob_Yes", ascending=False)

#         # ê²°ê³¼ í‘œì‹œ
#         st.subheader("ğŸ” ì˜ˆì¸¡ ê²°ê³¼ (ì´íƒˆ í™•ë¥  ë†’ì€ ìˆœ ìƒìœ„ 20ê°œ)")
#         st.dataframe(df_sorted.head(1000)[feature_columns + ["Prob_Yes", "Pred", "Grade"]])
        

#         # ë‹¤ìš´ë¡œë“œ
#         csv = df.to_csv(index=False).encode("utf-8-sig")
#         st.download_button("ğŸ“¥ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ", data=csv, file_name="predicted_attrition.csv", mime="text/csv")

#     except Exception as e:
#         st.error(f"âŒ ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")


import streamlit as st
import pandas as pd
import numpy as np
import joblib
import os
import pickle

#=======================================================
import sys
import os
# src ë””ë ‰í† ë¦¬ë¥¼ ì‹œìŠ¤í…œ ê²½ë¡œì— ì¶”ê°€
src_path = os.path.abspath('../notebooks/test/test_test/')
if src_path not in sys.path:
    sys.path.append(src_path)

from tools import drop_unnecessary_col,mapping
#=======================================================

# 2. ì €ì¥ëœ ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜¤ê¸°
with open('../notebooks/test/test_test/xgb_clf.pkl','rb') as f1:
    model = pickle.load(f1)
with open('../notebooks/test/test_test/dummy_scaler.pkl','rb') as f:
    scaler = pickle.load(f)

st.title("ğŸ“¦ ëŒ€ëŸ‰ ì´íƒˆ ì˜ˆì¸¡ (ì „ì²˜ë¦¬ ì™„ë£Œëœ CSV ì‚¬ìš©)")

batch_file = st.file_uploader("ëŒ€ëŸ‰ ë°ì´í„° íŒŒì¼ ì—…ë¡œë“œ", type=["csv"])

if batch_file:
    try:
        DF = pd.read_csv(batch_file)
        st.write("ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°", DF.head())

        # # 1. ëª¨ë¸ ë° feature ëª©ë¡ ë¶ˆëŸ¬ì˜¤ê¸°
        # @st.cache_resource
        # def load_model():
        #     return joblib.load("../notebooks/test/xgb.pkl")

        # @st.cache_resource
        # def load_feature_list():
        #     return joblib.load("../notebooks/test/preprocessed_columns.pkl")

        # model = load_model()
        # feature_columns = load_feature_list()


        # # 2. CSV íŒŒì¼ ê²½ë¡œ
        # csv_path = "../data/processed_datasets.csv"

        # if not os.path.exists(csv_path):
        #     st.error(f"âŒ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {csv_path}")
        # else:
        #     # ì „ì²˜ë¦¬ ì „ ì›ë³¸ ë°ì´í„° ë¡œë“œ
        #     df_raw = pd.read_csv(csv_path)
        #     # st.write("âœ… ì…ë ¥ ë°ì´í„° (ì›ë³¸)", df_raw.head())

        #     try:
        df = DF.copy()
        df = drop_unnecessary_col(df)
        df = mapping(df)
        norm = scaler.transform(df)
        norm_df = pd.DataFrame(norm, columns=df.columns)
        proba =  model.predict_proba(norm_df)[:,1]


                # # ì „ì²˜ë¦¬ (ì˜ˆì¸¡ìš© feature ë°ì´í„° ìƒì„±)
                # df = df_raw.copy()
                # for col in feature_columns:
                #     if col not in df.columns:
                #         df[col] = 0
                # X = df[feature_columns]

                # # ì˜ˆì¸¡
                # prob = model.predict_proba(X)[:, 1]
                # pred = (prob >= 0.5).astype(int)

        def categorize(p):
            if p >= 0.7: return "High"
            elif p >= 0.3: return "Medium"
            return "Low"

        DF['Attrition_Prob'] = np.round(proba,4)

                # # ì›ë³¸ ë°ì´í„°ì— ê²°ê³¼ ì¶”ê°€
                # df_raw["Prob_Yes"] = np.round(prob, 4)
        DF["Pred"] = np.where(proba>0.5, "ì´íƒˆ", "ì”ë¥˜")
        DF["Grade"] = [categorize(p) for p in proba]

                # í™•ë¥  ë†’ì€ ìˆœìœ¼ë¡œ ì •ë ¬
        df_sorted = DF.sort_values(by="Attrition_Prob", ascending=False)

                # ìƒìœ„ 20ê°œ ì¶œë ¥
        st.subheader("ğŸ” ì˜ˆì¸¡ ê²°ê³¼ (ì´íƒˆ í™•ë¥  ë†’ì€ ìˆœ Top 20)")
        st.dataframe(df_sorted.head(20))
            # st.dataframe(DF.head(1000)[feature_columns + ["Prob_Yes", "Pred", "Grade"]])  # Dropped Columns ìˆìŒ

        # ì „ì²´ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ
        csv = df_sorted.to_csv(index=False).encode("utf-8-sig")
        st.download_button("ğŸ“¥ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ", data=csv, file_name="predicted_attrition.csv", mime="text/csv")

    except Exception as e:
        st.error(f"âŒ ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")